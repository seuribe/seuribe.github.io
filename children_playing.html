<!DOCTYPE html>
<html lang="en">
  <title> </title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://unpkg.com/tachyons/css/tachyons.min.css">
  <body class="bg-black-10 dark-gray sans-serif">
	<div class="fl w-50">
	<article class="pa3 pa5-ns">
	  <h1 class="f3 f2-m f1-l">Children Playing</h1>
	  <p class="measure lh-copy tj">
A commonly held belief is that computers are infallible, with algorithms providing perfect answers to questions, and that replacing humans with AIs will make everything easier, faster and safer.
	  </p>
	  <p class="measure lh-copy tj">
But interpreting the world requires more than correct code execution: we need knowledge of it; and the more we try to incorporate AIs into our daily lives, the more information about the world that we need to feed them with. When providing this knowledge we are subject to the same problems that we have everywhere else, including bias, blindness and ignorance. And while sometimes this leads to funny misinterpretations, they can also have more serious consequences.
	  </p>
	  <p class="measure lh-copy tj">
In 2015 Google was at the center of a scandal when their image recognition service tagged black people as gorillas. The algorithm had been trained with images taken from the internet, where racist images are found at large. The algorithm did what it was created for: learned from examples, and applied what it learned to new images.
In 2018, after anti-inmigrations protests in the city of Chemnitz, Germany, a video showing a group of protesters chasing inmigrants appeared on social networks. Hans-Georg Maa&szlig;en, then President of the Federal Office for the Protection of the Constitution, denied seeing any indication of a 'Hetzjagd' (hunt) in the video or other media.
	  </p>
	  <p class="measure lh-copy tj">
Google's response, it was learned afterwards, was to simply remove the <i>gorilla</i> tag from all their pictures. Is it impossible even for Google - the single biggest investor in AI in the world - to deal with bias and racism? Are we supposed to depend on these same systems for critical decisions, like driving cars?  Maa&szlig;en was - leaving political interpretations aside - blind to the situation shown in the video. What will happen if decide to use AIs to detect situations of danger in the street? Who would train them, and which examples would they use?
</p>
	  <div class="measure f6">
		<i>Children Playing</i> was commissioned for the STEAM Hub Conference 2018, a gathering for the discussion science, technology, engineering, arts and mathematics in Science Communication.
		</div>

	  </article>
	</div>
	<div class="fl w-50 pa4 pt6 pr6">
		<img class="ma2" src="images/children_playing_1.jpeg"><br/>
		<img class="ma2" src="images/children_playing_2.jpeg"><br/>
		<img class="ma2" src="images/children_playing_3.jpeg"><br/>
	</div>
  </body>
</html>