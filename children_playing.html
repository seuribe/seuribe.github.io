<!DOCTYPE html>
<html lang="en">
  <title> </title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://unpkg.com/tachyons/css/tachyons.min.css">
  <body class="bg-black-10 dark-gray sans-serif">
	<article class="pa3 pa5-ns">
    <div class="flex flex-column flex-row-ns">	
	<div class="fl w-100 w-60-ns order-1 order-1-ns">
	  <h1 class="f3 f2-m f1-l">Children Playing</h1>
	  <p class="measure lh-copy tj">
A commonly held belief is that computers are infallible, with algorithms providing perfect answers to questions, and that replacing humans with AIs will make everything easier, faster and safer.
	  </p>
	  <p class="measure lh-copy tj">
But interpreting the world requires more than correct code execution: we need knowledge of it; and the more we try to incorporate AIs into our daily lives, the more information about the world that we need to feed them with. When providing this knowledge we are subject to the same problems that we have everywhere else, including bias, blindness and ignorance. And while sometimes this leads to funny misinterpretations, they can also have more serious consequences.
	  </p>
	  <p class="measure lh-copy tj">
In 2015 Google was at the center of a scandal when their image recognition service tagged black people as gorillas. The algorithm had been trained with images taken from the internet, where racist images are found at large. The algorithm did what it was created for: learned from the examples and applied that knowledge to classify new images.
In 2018, after anti-immigration protests in the city of Chemnitz, Germany, a video appeared on social networks showing a group of protesters chasing immigrants. Hans-Georg Maa&szlig;en, then President of the Federal Office for the Protection of the Constitution, denied seeing any indication of a 'Hetzjagd' (hunt) in the video or other media.
	  </p>
	  <p class="measure lh-copy tj">
Google's response, it was revealed afterwards, was to simply remove the <i>gorilla</i> tag from all their pictures. Is it impossible even for Google - the single biggest investor in AI in the world - to deal with bias and racism? Are we supposed to depend on these same systems for critical decisions, like driving cars?  Maa&szlig;en was - leaving political interpretations aside - blind to the situation shown in the video. What will happen if decide to use AIs to detect situations of danger in the street? Who would train them, and which examples would they use?
</p>
	  <div class="measure f6">
		<i>Children Playing</i> was commissioned for the STEAM Hub Conference 2018, a gathering for the discussion science, technology, engineering, arts and mathematics in Science Communication.
		</div>
	</div>
      <div class="pl3-ns order-2 order-2-ns mb4 mb0-ns w-70 w-70-ns">
		<img class="ma2" src="images/children_playing_1.webp"><br/>
		<img class="ma2" src="images/children_playing_2.webp"><br/>
		<img class="ma2" src="images/children_playing_3.webp"><br/>
	  </div>
	</div>
	  </article>
		<script data-goatcounter="https://suribe.goatcounter.com/count" async src="//gc.zgo.at/count.js"></script>
  </body>
</html>